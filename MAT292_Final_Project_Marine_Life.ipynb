{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63CwONZlM6jj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "=============================================================================\n",
        "           MARINE LIFE BIO-ACCUMULATION MODEL (RK4 + PINN)\n",
        "=============================================================================\n",
        "\n",
        "[1] USER GUIDE & INSTRUCTIONS\n",
        "-----------------------------------------------------------------------------\n",
        "This script simulates the biological impact of treated water release on marine life.\n",
        "Unlike the Water Model (passive dispersion), this models 'Bio-accumulation':\n",
        "the active uptake of radioactive isotopes by fish and their subsequent elimination.\n",
        "\n",
        "HOW TO OPERATE:\n",
        "1. Run the script. It is fully automated.\n",
        "   - Stage 1: Computes the coupled differential equations (Water + Fish).\n",
        "   - Stage 2: Trains the Neural Network (Log-Space training for stability).\n",
        "   - Stage 3: Generates a Linear Scale Heatmap (2025-2055).\n",
        "\n",
        "PREREQUISITES:\n",
        "   pip install numpy matplotlib torch\n",
        "\n",
        "Code Running Application:\n",
        "Google Colab is recommended to run this code. You can download the file and\n",
        "open it through Google Colab.\n",
        "\n",
        "[2] HOW TO INTERPRET THE RESULT\n",
        "-----------------------------------------------------------------------------\n",
        "The output is a Heatmap showing radioactivity in fish (Bq/kg).\n",
        "- X-Axis: Distance from Source (km).\n",
        "- Y-Axis: Time (Years).\n",
        "- Color:  Red/Orange = Active Uptake zone (~10-20 Bq/kg).\n",
        "          Blue = Safe/Background levels.\n",
        "- Key Event: Look for the white dotted line at 2051. You will see a sharp\n",
        "  drop in color intensity, representing the biological elimination (depuration)\n",
        "  after the discharge stops.\n",
        "\n",
        "[3] Limitations\n",
        "-----------------------------------------------------------------------------\n",
        "- NEURAL NETWORK: The accuracy depends on training. If 'Loss' remains high\n",
        "  (>0.1), re-run the script to re-initialize the random weights. No guarantee\n",
        "  that you can receive the exact same result due to Neural Network.\n",
        "- We recommend to run the training code twice to get a more precise code that\n",
        "  is similar to our results in the report.\n",
        "\n",
        "*** Gemini is used to generate the explanation and the guidelines for clarity.\n",
        "=============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: REALISTIC PHYSICS (Advection-Diffusion)\n",
        "# ==========================================\n",
        "# EXPLANATION: This function defines the \"Coupled System\" of equations.\n",
        "# We are solving for 4 variables simultaneously at every point in the ocean:\n",
        "# 1. W_cs: Water Concentration (Cesium)\n",
        "# 2. F_cs: Fish Concentration (Cesium)\n",
        "# 3. W_tr: Water Concentration (Tritium)\n",
        "# 4. F_tr: Fish Concentration (Tritium)\n",
        "def coupled_derivatives(t, state_vector, params):\n",
        "    N = params['N']\n",
        "    u, dx = params['u'], params['dx']\n",
        "\n",
        "    # DIFFUSION COEFFICIENT (Realistic: 50,000 km^2/yr)\n",
        "    # Represents the chaotic mixing of the ocean.\n",
        "    D = 50000.0\n",
        "\n",
        "    # ISOTOPES & BIOLOGICAL KINETICS\n",
        "    # lam: Radioactive decay rate (physics).\n",
        "    # k_up: Uptake rate (biology - how fast fish absorb it).\n",
        "    # k_elim: Elimination rate (biology - how fast fish pee/sweat it out).\n",
        "\n",
        "    # Cesium (2011 Legacy): High uptake, slow elimination (bio-accumulates).\n",
        "    lam_cs, k_up_cs, k_elim_cs = 0.023, 60.0, 1.0\n",
        "    # Tritium (ALPS): Lower uptake, fast elimination (does not accumulate much).\n",
        "    lam_tr, k_up_tr, k_elim_tr = 0.056, 30.0, 30.0\n",
        "\n",
        "    W_cs = state_vector[0:N]\n",
        "    F_cs = state_vector[N:2*N]\n",
        "    W_tr = state_vector[2*N:3*N]\n",
        "    F_tr = state_vector[3*N:4*N]\n",
        "\n",
        "    # SOURCES (Forcing Functions)\n",
        "    src_cs = 3000.0 if t <= 0.5 else 0          # 2011 Spike (Fukushima Accident)\n",
        "    src_tr = 400.0 if (12.0 <= t <= 40.0) else 0 # 2023-2051 Stream (ALPS Release)\n",
        "\n",
        "    # --- DERIVATIVES ---\n",
        "    dW_cs = np.zeros(N)\n",
        "    dW_tr = np.zeros(N)\n",
        "\n",
        "    # Boundary Conditions (Tank 0 - The Source)\n",
        "    # Change = Source - Outflow - Decay + Diffusion from neighbor\n",
        "    dW_cs[0] = src_cs - (u/dx)*W_cs[0] - lam_cs*W_cs[0] + (D/dx**2)*(W_cs[1] - W_cs[0])\n",
        "    dW_tr[0] = src_tr - (u/dx)*W_tr[0] - lam_tr*W_tr[0] + (D/dx**2)*(W_tr[1] - W_tr[0])\n",
        "\n",
        "    # Interior Tanks (The Open Ocean)\n",
        "    for i in range(1, N-1):\n",
        "        # Diffusion: (Neighbor_Left - 2*Current + Neighbor_Right)\n",
        "        diff_term = (D/dx**2) * (W_cs[i+1] - 2*W_cs[i] + W_cs[i-1])\n",
        "        # Advection: Current bringing stuff from the left\n",
        "        adv_term = (u/dx) * (W_cs[i-1] - W_cs[i])\n",
        "        dW_cs[i] = adv_term + diff_term - lam_cs*W_cs[i]\n",
        "\n",
        "        diff_term_tr = (D/dx**2) * (W_tr[i+1] - 2*W_tr[i] + W_tr[i-1])\n",
        "        adv_term_tr = (u/dx) * (W_tr[i-1] - W_tr[i])\n",
        "        dW_tr[i] = adv_term_tr + diff_term_tr - lam_tr*W_tr[i]\n",
        "\n",
        "    # Last Tank (Boundary Condition - Outflow)\n",
        "    dW_cs[-1] = (u/dx)*(W_cs[-2] - W_cs[-1]) - lam_cs*W_cs[-1]\n",
        "    dW_tr[-1] = (u/dx)*(W_tr[-2] - W_tr[-1]) - lam_tr*W_tr[-1]\n",
        "\n",
        "    # Fish Dynamics (The Biological Equation)\n",
        "    # dFish/dt = (Uptake from Water) - (Elimination) - (Decay)\n",
        "    dF_cs = (k_up_cs * W_cs) - (k_elim_cs * F_cs) - (lam_cs * F_cs)\n",
        "    dF_tr = (k_up_tr * W_tr) - (k_elim_tr * F_tr) - (lam_tr * F_tr)\n",
        "\n",
        "    return np.concatenate((dW_cs, dF_cs, dW_tr, dF_tr))\n",
        "\n",
        "def generate_realistic_data():\n",
        "    params = {'N': 60, 'u': 2800.0, 'dx': 170.0}\n",
        "    dt = 0.05\n",
        "    T_max = 50.0\n",
        "    time_vec = np.linspace(0, T_max, int(T_max/dt))\n",
        "\n",
        "    state = np.zeros(4 * params['N'])\n",
        "    history = np.zeros((len(time_vec), 4 * params['N']))\n",
        "\n",
        "    # SOLVER: Runge-Kutta 4 Loop\n",
        "    for i, t in enumerate(time_vec[:-1]):\n",
        "        history[i] = state\n",
        "        k1 = coupled_derivatives(t, state, params)\n",
        "        k2 = coupled_derivatives(t + 0.5*dt, state + 0.5*dt*k1, params)\n",
        "        k3 = coupled_derivatives(t + 0.5*dt, state + 0.5*dt*k2, params)\n",
        "        k4 = coupled_derivatives(t + dt, state + dt*k3, params)\n",
        "        state = state + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
        "\n",
        "    history[-1] = state\n",
        "    return time_vec, history, params\n",
        "\n",
        "print(\"1. Running Diffusion Physics Model...\")\n",
        "rk4_time, rk4_data, params = generate_realistic_data()\n",
        "\n",
        "# EXPLANATION: Helper to sum up Cesium + Tritium in fish\n",
        "def get_total_fish_bq(dist_km, t_year):\n",
        "    max_dist = params['N'] * params['dx']\n",
        "    # Small epsilon to avoid log(0) errors later\n",
        "    min_val = 1e-4\n",
        "    if t_year <= 0 or dist_km > max_dist: return min_val\n",
        "    t_idx = int(t_year / 0.05)\n",
        "    if t_idx >= len(rk4_time): t_idx = -1\n",
        "    tank_idx = int(dist_km / params['dx'])\n",
        "    if tank_idx >= params['N']: return min_val\n",
        "\n",
        "    idx_fish_cs = params['N'] + tank_idx\n",
        "    idx_fish_tr = 3*params['N'] + tank_idx\n",
        "    total = rk4_data[t_idx, idx_fish_cs] + rk4_data[t_idx, idx_fish_tr]\n",
        "    return max(total, min_val)\n",
        "\n",
        "# ==========================================\n",
        "# PART 2: TRAIN AI (Log-Train for Stability)\n",
        "# ==========================================\n",
        "print(\"2. Training AI...\")\n",
        "n_samples = 8000\n",
        "x_train = np.random.uniform(0, 10000, n_samples)\n",
        "t_train = np.random.uniform(0.1, 50, n_samples)\n",
        "y_train = np.array([get_total_fish_bq(d, t) for d, t in zip(x_train, t_train)])\n",
        "\n",
        "# EXPLANATION: Logarithmic Transformation\n",
        "# Radiation varies from 0.0001 to 100.0. Linear training fails on this range.\n",
        "# We compress the target data: y_new = log10(y_old).\n",
        "# This allows the AI to learn both trace amounts and peak amounts equally well.\n",
        "y_train_log = np.log10(y_train)\n",
        "x_mean, x_std = x_train.mean(), x_train.std()\n",
        "t_mean, t_std = t_train.mean(), t_train.std()\n",
        "y_log_mean, y_log_std = y_train_log.mean(), y_train_log.std()\n",
        "\n",
        "X_tensor = torch.tensor(np.column_stack(((x_train-x_mean)/x_std, (t_train-t_mean)/t_std)), dtype=torch.float32)\n",
        "Y_tensor = torch.tensor((y_train_log - y_log_mean)/y_log_std, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 128), nn.Tanh(),\n",
        "    nn.Linear(128, 128), nn.Tanh(),\n",
        "    nn.Linear(128, 64), nn.Tanh(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for i in range(1500):\n",
        "    optimizer.zero_grad()\n",
        "    loss = nn.MSELoss()(model(X_tensor), Y_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# ==========================================\n",
        "# PART 3: LINEAR SCALE MAP\n",
        "# ==========================================\n",
        "print(\"3. Generating Linear Scale Map...\")\n",
        "\n",
        "start_year = 2025\n",
        "end_year = 2055\n",
        "sim_start = start_year - 2011\n",
        "sim_end = end_year - 2011\n",
        "\n",
        "dist_vals = np.linspace(0, 10000, 300)\n",
        "time_vals = np.linspace(sim_start, sim_end, 300)\n",
        "D_grid, T_grid = np.meshgrid(dist_vals, time_vals)\n",
        "\n",
        "d_flat, t_flat = D_grid.flatten(), T_grid.flatten()\n",
        "inputs = np.column_stack(((d_flat - x_mean)/x_std, (t_flat - t_mean)/t_std))\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds_log_norm = model(torch.tensor(inputs, dtype=torch.float32)).numpy().flatten()\n",
        "\n",
        "# EXPLANATION: Inverse Transformation\n",
        "# We must convert the AI's log-prediction back to real numbers (Bq/kg).\n",
        "# 1. Un-normalize: (Pred * std) + mean\n",
        "# 2. Un-log: 10^x\n",
        "preds_raw = 10**((preds_log_norm * y_log_std) + y_log_mean)\n",
        "Z_grid = preds_raw.reshape(D_grid.shape)\n",
        "\n",
        "# LINEAR PLOTTING LOGIC\n",
        "# We clamp the Scale to 20.0 Bq/kg.\n",
        "# Why? Even if some points hit 25, clamping at 20 makes the\n",
        "# \"10-20 Bq/kg\" steady state zone appear visually distinct (Red).\n",
        "plot_vmax = 20.0\n",
        "plot_vmin = 0.0\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Removed LogNorm. Using standard linear normalization.\n",
        "plt.imshow(Z_grid, aspect='auto', origin='lower', cmap='turbo',\n",
        "           extent=[0, 10000, start_year, end_year],\n",
        "           vmin=plot_vmin, vmax=plot_vmax)\n",
        "\n",
        "cb = plt.colorbar()\n",
        "cb.set_label('Total Radioactivity (Bq/kg) [Linear Scale]', rotation=270, labelpad=20)\n",
        "\n",
        "plt.xlabel('Distance from Japan (km)')\n",
        "plt.ylabel('Prediction Year')\n",
        "plt.title(f'Future Prediction (Linear Scale): {start_year}-{end_year}')\n",
        "\n",
        "plt.axhline(y=2025, color='white', linestyle='-', linewidth=2)\n",
        "plt.text(200, 2025.5, 'CURRENT STATE', color='white', fontweight='bold', fontsize=8)\n",
        "\n",
        "plt.axhline(y=2051, color='white', linestyle=':', linewidth=2)\n",
        "plt.text(200, 2051.5, 'DISCHARGE ENDS', color='white', fontweight='bold', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "=============================================================================\n",
        "             PART 4: STATISTICAL VALIDATION (MARINE MODEL)\n",
        "=============================================================================\n",
        "\n",
        "[1] SCIENTIFIC OBJECTIVE\n",
        "-----------------------------------------------------------------------------\n",
        "This module performs a rigorous statistical audit of the Neural Network.\n",
        "Because biological systems are non-linear (uptake vs. elimination), we need\n",
        "to verify that the AI captures these dynamics accurately.\n",
        "\n",
        "We use two standard metrics:\n",
        "1. PARITY PLOT (Left Panel):\n",
        "   - Compares AI Predictions (Y-axis) vs. Physics Truth (X-axis).\n",
        "   - A perfect model forms a straight diagonal line ($y=x$).\n",
        "   - Deviations show where the AI struggles (e.g., at very low concentrations).\n",
        "\n",
        "2. RESIDUAL HISTOGRAM (Right Panel):\n",
        "   - Shows the distribution of errors (Prediction - Truth).\n",
        "   - We want a sharp peak at 0. This proves the model is \"Unbiased\".\n",
        "\n",
        "[2] CRITICAL STEP: REVERSE-LOG TRANSFORMATION\n",
        "-----------------------------------------------------------------------------\n",
        "Recall that we trained the model on Log10 data to handle small numbers.\n",
        "To evaluate accuracy in the Real World, we must:\n",
        "   1. Take the AI output (Log Normalized).\n",
        "   2. Un-normalize it.\n",
        "   3. Raise it to power of 10 ($10^x$) to get Bq/kg.\n",
        "\n",
        "[3] PREREQUISITES\n",
        "-----------------------------------------------------------------------------\n",
        "- The variable 'model' must be a trained PyTorch neural network. You must run\n",
        "the first part of the script to train the AI and then initiate this program. If\n",
        "not, the code will not run because it is based on the previous result. If run\n",
        "time lost happened, you must rerun the first part and then initiate this part.\n",
        "\n",
        "Code Running Application:\n",
        "Google Colab is recommended to run this code. You can download the file and\n",
        "open it through Google Colab.\n",
        "\n",
        "*** Gemini is used to generate the explanation and the guidelines for clarity.\n",
        "=============================================================================\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import torch\n",
        "\n",
        "# ==========================================\n",
        "# 1. GENERATE TEST DATA (Marine Model)\n",
        "# ==========================================\n",
        "# EXPLANATION: We generate 2000 NEW random points.\n",
        "# We include t=50 years to specifically test if the AI learned the\n",
        "# \"Drop-off\" phase (Depuration) after the discharge stops in 2051.\n",
        "n_test = 2000\n",
        "x_test = np.random.uniform(0, 10000, n_test)\n",
        "t_test = np.random.uniform(0.1, 50, n_test)\n",
        "\n",
        "# GET GROUND TRUTH (Physics Engine)\n",
        "# Using 'get_total_fish_bq' from your Marine Code\n",
        "y_true = np.array([get_total_fish_bq(d, t) for d, t in zip(x_test, t_test)])\n",
        "\n",
        "# GET PREDICTION (Neural Network)\n",
        "# Use the training stats from your Marine Model block\n",
        "# (x_mean, x_std, t_mean, t_std must match the ones used in Marine training)\n",
        "# Recalculating approx stats based on the training range (0-10000 km, 0-50 yr)\n",
        "x_mean_m, x_std_m = 5000.0, 2886.0\n",
        "t_mean_m, t_std_m = 25.0, 14.4\n",
        "\n",
        "inputs = np.column_stack(((x_test - x_mean_m)/x_std_m, (t_test - t_mean_m)/t_std_m))\n",
        "\n",
        "with torch.no_grad():\n",
        "    preds_norm = model(torch.tensor(inputs, dtype=torch.float32)).numpy().flatten()\n",
        "\n",
        "# REVERSE LOG TRANSFORMATION\n",
        "# EXPLANATION: This is the most critical step for this specific model.\n",
        "# The network predicts 'Normalized Logarithms'. We must reverse the math\n",
        "# to compare apples-to-apples (Bq/kg vs Bq/kg).\n",
        "# y_pred = 10 ^ ( (Output * Std) + Mean )\n",
        "y_true_log = np.log10(y_true)\n",
        "y_log_mean_m = y_true_log.mean()\n",
        "y_log_std_m = y_true_log.std()\n",
        "\n",
        "# Un-normalize: (Pred * Std) + Mean\n",
        "preds_log = (preds_norm * y_log_std_m) + y_log_mean_m\n",
        "# Un-log: 10^x\n",
        "y_pred = 10**preds_log\n",
        "\n",
        "# ==========================================\n",
        "# 2. CALCULATE METRICS\n",
        "# ==========================================\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "residuals = y_pred - y_true\n",
        "\n",
        "# ==========================================\n",
        "# 3. PLOT EVALUATION\n",
        "# ==========================================\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# --- PANEL 1: PARITY PLOT ---\n",
        "\n",
        "ax1.scatter(y_true, y_pred, alpha=0.5, s=15, c='darkorange', edgecolor='k', linewidth=0.3, label='Test Points')\n",
        "# Plot the 45-degree \"Perfect Fit\" line\n",
        "max_axis = max(y_true.max(), y_pred.max())\n",
        "ax1.plot([0, max_axis], [0, max_axis], 'k--', linewidth=2, label='Ideal ($y=x$)')\n",
        "\n",
        "ax1.set_title(f'Marine Life Model Accuracy\\n$R^2$ Score = {r2:.4f}', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlabel('Physics Ground Truth (Bq/kg)', fontsize=12)\n",
        "ax1.set_ylabel('Neural Network Prediction (Bq/kg)', fontsize=12)\n",
        "ax1.legend()\n",
        "ax1.grid(True, linestyle=':', alpha=0.6)\n",
        "\n",
        "# --- PANEL 2: ERROR HISTOGRAM ---\n",
        "ax2.hist(residuals, bins=40, color='orangered', alpha=0.7, edgecolor='black')\n",
        "ax2.axvline(0, color='black', linestyle='--', linewidth=2, label='Zero Error')\n",
        "\n",
        "ax2.set_title(f'Residual Error Distribution\\nMSE = {mse:.5f}', fontsize=14, fontweight='bold')\n",
        "ax2.set_xlabel('Prediction Error (Bq/kg)', fontsize=12)\n",
        "ax2.set_ylabel('Frequency', fontsize=12)\n",
        "ax2.legend()\n",
        "ax2.grid(True, linestyle=':', alpha=0.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2er2nfahS-qd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}